from fastapi import FastAPI, Depends, HTTPException
from sqlalchemy import create_engine, Column, Integer, String, DateTime, text
from sqlalchemy.schema import FetchedValue
from sqlalchemy.orm import sessionmaker, declarative_base, Session
from pydantic import BaseModel
from datetime import datetime
from typing import Optional
import os
import urllib.parse
from dotenv import load_dotenv  

load_dotenv()

# ==========================================
# 1. AZURE SQL DATABASE SETUP 
# ==========================================
# Updated with your active SQL authentication credentials
raw_connection_string = os.getenv(
    "AZURE_SQL_CONNECTION_STRING"
)

params = urllib.parse.quote_plus(raw_connection_string)
SQLALCHEMY_DATABASE_URL = f"mssql+pyodbc:///?odbc_connect={params}"

engine = create_engine(SQLALCHEMY_DATABASE_URL)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base = declarative_base()

# ==========================================
# 2. DATABASE MODEL (Matches your SQL Table)
# ==========================================
class MigrationJob(Base):
    __tablename__ = "MigrationJobs"

    Id = Column(Integer, primary_key=True, index=True)
    UserId = Column(String(128), index=True, nullable=False)
    ReportName = Column(String(255), nullable=False)
    ReportPath = Column(String(500))
    SourceReportId = Column(String(100))
    SourcePlatform = Column(String(50), nullable=False)
    TargetPlatform = Column(String(50), default='Power BI')
    MigrationStatus = Column(String(20), default='Pending')
    ErrorMessage = Column(String)
    
    # Let SQL Server handle the default timestamps
    StartedAt = Column(DateTime, server_default=text("SYSUTCDATETIME()"))
    CompletedAt = Column(DateTime, nullable=True)
    
    # FetchedValue() tells SQLAlchemy this is a computed column generated by the database
    DurationMinutes = Column(Integer, FetchedValue()) 
    
    SheetsCount = Column(Integer, default=0)
    DashboardsCount = Column(Integer, default=0)
    WorkbooksCount = Column(Integer, default=0)

# ==========================================
# 3. PYDANTIC SCHEMAS (Data Validation)
# ==========================================
class JobCreate(BaseModel):
    UserId: str
    ReportName: str
    SourcePlatform: str
    ReportPath: Optional[str] = None
    SourceReportId: Optional[str] = None
    TargetPlatform: Optional[str] = "Power BI"
    SheetsCount: Optional[int] = 0
    DashboardsCount: Optional[int] = 0
    WorkbooksCount: Optional[int] = 0

class JobUpdate(BaseModel):
    MigrationStatus: str
    ErrorMessage: Optional[str] = None
    CompletedAt: Optional[datetime] = None

class JobResponse(BaseModel):
    Id: int
    UserId: str
    ReportName: str
    ReportPath: Optional[str] = None
    SourceReportId: Optional[str] = None
    SourcePlatform: str
    TargetPlatform: str
    MigrationStatus: str
    ErrorMessage: Optional[str] = None
    StartedAt: datetime
    CompletedAt: Optional[datetime] = None
    DurationMinutes: Optional[int] = None
    SheetsCount: int
    DashboardsCount: int
    WorkbooksCount: int

    class Config:
        from_attributes = True

# ==========================================
# 4. FASTAPI APP & ENDPOINTS
# ==========================================
app = FastAPI(title="Migration Tracker API")


# 2. Add this exact block right below app = FastAPI(...)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], # Allows all frontends to connect (perfect for testing)
    allow_credentials=True,
    allow_methods=["*"], # Allows GET, POST, PUT, DELETE
    allow_headers=["*"],
)

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

# --- CREATE (POST) ---
@app.post("/jobs/", response_model=JobResponse)
def create_job(job: JobCreate, db: Session = Depends(get_db)):
    db_job = MigrationJob(**job.model_dump())
    db.add(db_job)
    db.commit()
    db.refresh(db_job) 
    return db_job

# --- READ (GET) BY USERNAME/EMAIL ---
@app.get("/jobs/user/{user_id}", response_model=list[JobResponse])
def get_jobs_by_user(user_id: str, db: Session = Depends(get_db)):
    jobs = db.query(MigrationJob).filter(MigrationJob.UserId == user_id).all()
    return jobs

# --- UPDATE (PUT) ---
@app.put("/jobs/{job_id}", response_model=JobResponse)
def update_job_status(job_id: int, job_update: JobUpdate, db: Session = Depends(get_db)):
    db_job = db.query(MigrationJob).filter(MigrationJob.Id == job_id).first()
    
    if db_job is None:
        raise HTTPException(status_code=404, detail="Job not found")
        
    db_job.MigrationStatus = job_update.MigrationStatus
    db_job.ErrorMessage = job_update.ErrorMessage
    db_job.CompletedAt = job_update.CompletedAt
    
    db.commit()
    db.refresh(db_job)
    return db_job

# --- DELETE (REMOVE) ---
@app.delete("/jobs/{job_id}")
def delete_job(job_id: int, db: Session = Depends(get_db)):
    db_job = db.query(MigrationJob).filter(MigrationJob.Id == job_id).first()
    
    if db_job is None:
        raise HTTPException(status_code=404, detail="Job not found")
        
    db.delete(db_job)
    db.commit()
    return {"message": f"Job {job_id} deleted successfully"}
